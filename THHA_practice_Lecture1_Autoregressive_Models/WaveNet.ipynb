{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Packages"
      ],
      "metadata": {
        "id": "lUaxPRwZwBsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "30xcQAsJwBze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data"
      ],
      "metadata": {
        "id": "xeymw-FAxjbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = 128\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                               transforms.Lambda(lambda x: x.round())])\n",
        "\n",
        "train_set = torchvision.datasets.MNIST(root=\"./data\",\n",
        "                                       train=True,\n",
        "                                       download=True,\n",
        "                                       transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_set,\n",
        "                                          batch_size=batch,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=2)"
      ],
      "metadata": {
        "id": "sYhJFgevxjCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Network"
      ],
      "metadata": {
        "id": "EoV7pjD1xk-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def append_location(x, device):\n",
        "  \"\"\"\n",
        "    Append location of pixels to the images.\n",
        "  \"\"\"\n",
        "  idxs = torch.arange(x.shape[-1])/27\n",
        "  grid = torch.meshgrid(idxs, idxs)\n",
        "  locations = torch.stack(grid, dim=0) # 2, x.shape[1], x.shape[1] (Stack: concatenate along a new dimension)\n",
        "  locations = locations.repeat(x.shape[0], 1, 1, 1) # batch_size, 2, x.shape[1], x.shape[1]\n",
        "  x = torch.cat((x, locations.to(device)), dim = 1) # batch_size, x.shape[0] + 2, x.shape[1], x.shape[2]\n",
        "  return x"
      ],
      "metadata": {
        "id": "aFsbidAUxkZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DilatedCausalConv1d(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, dilation=1):\n",
        "    super().__init__()\n",
        "    self.dilation = dilation\n",
        "    self.conv = nn.Conv1d(in_channels,\n",
        "                          out_channels,\n",
        "                          kernel_size=2,\n",
        "                          dilation=dilation,\n",
        "                          padding=0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "      Input: batch, in_channels, sequence_length\n",
        "    \"\"\"\n",
        "    x = self.conv(F.pad(x, [self.dilation, 0]))\n",
        "    return x # batch, out_channels, sequence_length\n",
        "\n",
        "class CausalConv1d(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, dilation=1):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv1d(in_channels,\n",
        "                          out_channels,\n",
        "                          kernel_size=2,\n",
        "                          dilation=dilation,\n",
        "                          padding=0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "      Input: batch, in_channels, sequence_length\n",
        "    \"\"\"\n",
        "    return self.conv(F.pad(x, [2, 0]))[:,:, :-1] # batch, out_channels, sequence_length"
      ],
      "metadata": {
        "id": "4jYIsOo50US6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, residual_channels, dilation=1):\n",
        "    super().__init__()\n",
        "    self.dilate = DilatedCausalConv1d(residual_channels, 2*residual_channels, dilation)\n",
        "    self.conv1d = nn.Conv1d(residual_channels, residual_channels, kernel_size=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "      Input: x # batch, residual_channels, sequence_length\n",
        "    \"\"\"\n",
        "    o = self.dilate(x)\n",
        "    o1, o2 = o.chunk(2, dim=1)\n",
        "    # print(\"o1 \",o1.shape)\n",
        "    # print('o2 ', o2.shape)\n",
        "    o = torch.tanh(o1) * torch.sigmoid(o2)\n",
        "    x = x + self.conv1d(o)\n",
        "    return x # batch, residual_channels, sequence_length"
      ],
      "metadata": {
        "id": "0RQTQaCUMeNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WaveNet(nn.Module):\n",
        "  def __init__(self, input_size, residual_channels, device, append_loc=True):\n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "    self.layers = 9\n",
        "    self.residual_channels = residual_channels\n",
        "    self.device = device\n",
        "    self.append_loc = append_loc\n",
        "\n",
        "    if self.append_loc:\n",
        "      self.causal_conv = CausalConv1d(self.input_size[0]+2, self.residual_channels)\n",
        "    else:\n",
        "      self.causal_conv = CausalConv1d(self.input_size[0], self.residual_channels)\n",
        "\n",
        "    res_blocks = []\n",
        "    for i in range(self.layers):\n",
        "      res_blocks.append(ResidualBlock(self.residual_channels, dilation=2**i))\n",
        "    self.stacked_res_blocks = nn.Sequential(*res_blocks)\n",
        "\n",
        "    self.out_conv = nn.Sequential(nn.Conv1d(self.residual_channels, self.input_size[0], kernel_size=1))\n",
        "                                  # nn.ReLU(),\n",
        "                                  # nn.Conv1d(self.input_size[0], self.input_size[0], kernel_size=1))\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "      Input: x    # batch, channels, height, width\n",
        "    \"\"\"\n",
        "    batch = x.shape[0]\n",
        "    x = append_location(x, self.device) if self.append_loc else x\n",
        "    x = x.view(batch, -1, self.input_size[1]*self.input_size[2]) # batch, in_channels, sequence_length\n",
        "\n",
        "    x = self.causal_conv(x) # batch, residual_channels, sequence_length\n",
        "    x = self.stacked_res_blocks(x) # batch, residual_channels, sequence_length\n",
        "    x = self.out_conv(x) # batch, out_channels, sequence_length\n",
        "    return x.view(batch, self.input_size[0], self.input_size[1], self.input_size[2]) # batch, channels, height, width\n",
        "\n",
        "  def sample(self, n):\n",
        "    with torch.no_grad():\n",
        "      x = torch.zeros(n, self.input_size[0], self.input_size[1], self.input_size[2]).to(self.device)\n",
        "      for i in range(self.input_size[1]):\n",
        "        for j in range(self.input_size[2]):\n",
        "          logits = self.forward(x)[:, :, i, j]\n",
        "          probs = torch.sigmoid(logits)\n",
        "          x[:, :, i, j] = torch.bernoulli(probs)\n",
        "    return x.cpu() # n, channels, height, width"
      ],
      "metadata": {
        "id": "2tK8ZS-KPX3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "init model"
      ],
      "metadata": {
        "id": "Q-9nzOHOYiGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
        "model = WaveNet((1, 28, 28), 64, device).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "S4zYvrMGYjjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training loop"
      ],
      "metadata": {
        "id": "HGHhqIpOYfVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "loss_values = []\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "  for i, (imgs, _) in enumerate(trainloader):\n",
        "    x = imgs.to(device)\n",
        "    targets = imgs.to(device)\n",
        "    probs = torch.sigmoid(model(x))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = F.binary_cross_entropy(probs, targets)\n",
        "    # loss = model.nll(x)\n",
        "    loss_values.append(loss.item())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1)%100==0:\n",
        "      print(f'Epoch [{epoch}/{epochs}], Step: [{i+1 }/{len(trainloader)}], Time {datetime.datetime.now()}, Loss {loss.item()}')\n",
        "\n",
        "  if epoch in [1, 4, 10, 14, 18, 20]:\n",
        "    torch.save(model.state_dict(), f'/content/wavenet_epoch{epoch}.pth')\n",
        "    samples = model.sample(16)\n",
        "    for j in range(16):\n",
        "      plt.subplot(4, 4, j+1)\n",
        "      plt.imshow(samples[j, :, :, :].view(1, 28, 28).permute(1, 2, 0).numpy())\n",
        "      plt.axis('off')\n",
        "    plt.savefig(f'/content/sampled_imgs_epoch{epoch}.png')\n",
        "\n",
        "print('Finish training')\n",
        "plt.plot(loss_values)\n",
        "plt.savefig('/content/loss_function.png')"
      ],
      "metadata": {
        "id": "yswtcH93YgrQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}